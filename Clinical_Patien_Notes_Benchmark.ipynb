{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/python_ML/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, AdamW\n",
    "import numpy as np\n",
    "import ast # For safely evaluating string representations of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global defined labels necessary for the sequencing \n",
    "\n",
    "LABEL_LIST = ['O', 'B-FEATURE', 'I-FEATURE']\n",
    "LABEL_MAP = {label: i for i, label in enumerate(LABEL_LIST)}\n",
    "IGNORE_LABEL_ID = -100 # Standard-Ignore-Index für CrossEntropyLoss in PyTorch\n",
    "\n",
    "def preprocess_data_for_token_classification(df, tokenizer, max_len):\n",
    "   \n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_labels = []\n",
    "    # Optional: map original data for evaluatin or debugging\n",
    "    # all_offset_mappings = [] \n",
    "    # all_example_ids = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        question = str(row['feature_text'])\n",
    "        context = str(row['pn_history'])\n",
    "        location_str = str(row['location'])\n",
    "\n",
    "        # Tokenization\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            question,\n",
    "            context,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\", \n",
    "            return_offsets_mapping=True,\n",
    "            return_attention_mask=True\n",
    "            # return_tensors=\"pt\" \n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        offset_mapping = encoding['offset_mapping'] # List (char_start, char_end) for each token\n",
    "\n",
    "        token_labels = [IGNORE_LABEL_ID] * len(input_ids)\n",
    "        \n",
    "        # `sequence_ids` helps to differentiate between:\n",
    "        # None: [CLS], [SEP], [PAD]\n",
    "        # 0: question (feature_text)\n",
    "        # 1: context (pn_history)\n",
    "        sequence_ids = encoding.sequence_ids()\n",
    "\n",
    "        # setting all context tokens to 1\n",
    "        for i in range(len(input_ids)):\n",
    "            if sequence_ids[i] == 1: # Token gehört zum Kontext (pn_history)\n",
    "                token_labels[i] = LABEL_MAP['O']\n",
    "        \n",
    "        # Location-String (parsing) \n",
    "        try:\n",
    "            char_spans = ast.literal_eval(location_str) \n",
    "        except (ValueError, SyntaxError):\n",
    "            char_spans = []\n",
    "\n",
    "        parsed_char_spans = []\n",
    "        for span_str in char_spans:\n",
    "            try:\n",
    "                start_char, end_char = map(int, span_str.split())\n",
    "                if start_char < end_char : \n",
    "                    parsed_char_spans.append((start_char, end_char))\n",
    "            except ValueError:\n",
    "                continue \n",
    "\n",
    "        # Setting B- and I-Feature for each annotation span \n",
    "        for start_char, end_char in parsed_char_spans:\n",
    "            first_token_in_current_span = True\n",
    "            for token_idx in range(len(input_ids)):\n",
    "                if sequence_ids[token_idx] != 1: \n",
    "                    continue\n",
    "\n",
    "                token_char_start, token_char_end = offset_mapping[token_idx]\n",
    "\n",
    "                # ignoring special tokens or tokens without valid Offset-Mapping in the context\n",
    "                if token_char_start == token_char_end == 0: \n",
    "                    continue\n",
    "                \n",
    "                # Check for an overlapping of the token with the char_span\n",
    "                # A token is a part of the span, if there is at least one shared character \n",
    "                if max(token_char_start, start_char) < min(token_char_end, end_char):\n",
    "                    if first_token_in_current_span:\n",
    "                        token_labels[token_idx] = LABEL_MAP['B-FEATURE']\n",
    "                        first_token_in_current_span = False\n",
    "                    else:\n",
    "                        # overrite 'O' or 'I-FEATURE'\n",
    "                        if token_labels[token_idx] != LABEL_MAP['B-FEATURE']:\n",
    "                             token_labels[token_idx] = LABEL_MAP['I-FEATURE']\n",
    "        \n",
    "        all_input_ids.append(torch.tensor(input_ids))\n",
    "        all_attention_masks.append(torch.tensor(attention_mask))\n",
    "        all_labels.append(torch.tensor(token_labels))\n",
    "        # all_offset_mappings.append(offset_mapping) # Falls für spätere Analyse benötigt\n",
    "        # all_example_ids.append(row['id'])\n",
    "\n",
    "    inputs_list = []\n",
    "    for i in range(len(all_input_ids)):\n",
    "        inputs_list.append({\n",
    "            'input_ids': all_input_ids[i],\n",
    "            'attention_mask': all_attention_masks[i]\n",
    "            # Optional: 'offset_mapping': all_offset_mappings[i], 'example_id': all_example_ids[i]\n",
    "        })\n",
    "        \n",
    "    return inputs_list, all_labels # all_labels is a list of label-tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientNotesTokenClassificationDataset(Dataset):\n",
    "    def __init__(self, encodings_list, labels_list): \n",
    "        self.encodings_list = encodings_list\n",
    "        self.labels_list = labels_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.encodings_list[idx] \n",
    "        item['labels'] = self.labels_list[idx] \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_train_val_test_split(df, train_size=0.8, val_size=0.1, test_size=0.1, random_state=42):\n",
    "    \n",
    "    if not (train_size + val_size + test_size == 1.0):\n",
    "        raise ValueError(\"The sum of train_size, val_size and test_size must be 1.0.\")\n",
    "\n",
    "    traintemp_df, temp_df = train_test_split(\n",
    "        df,\n",
    "        train_size=train_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    relative_val_size = val_size / (val_size + test_size)\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        train_size=relative_val_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    return traintemp_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # Optional, für eine schönere Batch-Fortschrittsanzeige\n",
    "\n",
    "def train_bert_token_classification_model(train_dataloader, val_dataloader, model, optimizer, device, epochs=3):\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train() \n",
    "        total_train_loss = 0\n",
    "        print(f\"\\n--- Epoch {epoch + 1}/{epochs} ---\")\n",
    "        \n",
    "        # progress bar of the training \n",
    "        train_progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
    "        \n",
    "        # training\n",
    "        for batch_idx, batch in enumerate(train_progress_bar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device) # Geänderte Label-Struktur\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels # Labels für Token-Klassifikation\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            # logits = outputs.logits # Shape: (batch_size, seq_length, num_labels)\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update der tqdm Fortschrittsanzeige mit dem aktuellen Loss\n",
    "            train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch + 1} - Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # validation\n",
    "        model.eval() \n",
    "        total_val_loss = 0\n",
    "        \n",
    "        val_progress_bar = tqdm(val_dataloader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
    "\n",
    "        with torch.no_grad(): # Keine Gradientenberechnung während der Validierung\n",
    "            for batch_idx, batch in enumerate(val_progress_bar):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device) # Geänderte Label-Struktur\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels # Labels für Token-Klassifikation\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                total_val_loss += loss.item()\n",
    "                val_progress_bar.set_postfix({'val_loss': loss.item()})\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        print(f\"Epoch {epoch + 1} - Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:60: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:63: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:63: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/var/folders/rq/0tfx_gzn2tl1v1h_cpzkkdn40000gn/T/ipykernel_50759/2149668446.py:60: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\"\\ MPS used\")\n",
      "/var/folders/rq/0tfx_gzn2tl1v1h_cpzkkdn40000gn/T/ipykernel_50759/2149668446.py:63: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(\"\\ CPU used\")\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the merged data set: (14300, 8)\n",
      "Verwende Sample von 2000 für Training/Validierung.\n",
      "Size of the train split: (1600, 8)\n",
      "Size of the validation split: (299, 8)\n",
      "Size of the test split: (101, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/python_ML/lib/python3.12/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ MPS used\n",
      "\n",
      "Starte Training für Token Classification...\n",
      "\n",
      "--- Epoch 1/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Training Loss: 0.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Validation Loss: 0.0479\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Epoch 2/2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Average Training Loss: 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Average Validation Loss: 0.0322\n",
      "--------------------------------------------------\n",
      "Training finished.\n",
      "Token Classification Training abgeschlossen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "    MAX_LEN = 256  \n",
    "    BATCH_SIZE = 8 \n",
    "    EPOCHS = 2\n",
    "\n",
    "    # Model initialization \n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "        BERT_MODEL_NAME,\n",
    "        num_labels=len(LABEL_LIST)\n",
    "    )\n",
    "\n",
    "    # Data loading\n",
    "    DATA_PATH = \"nbme-score-clinical-patient-notes/\" # Passe dies an\n",
    " \n",
    "    features_df = pd.read_csv(f\"{DATA_PATH}features.csv\")\n",
    "    notes_df = pd.read_csv(f\"{DATA_PATH}patient_notes.csv\")\n",
    "    train_df_raw = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "\n",
    "    merged_df = train_df_raw.merge(features_df, on=['feature_num', 'case_num'], how='left') \\\n",
    "                            .merge(notes_df, on=['pn_num', 'case_num'], how='left')\n",
    "\n",
    "    print(f\"Size of the merged data set: {merged_df.shape}\")\n",
    "    merged_df.dropna(subset=['pn_history', 'feature_text', 'location'], inplace=True) # Robuster: Notwendige Spalten prüfen\n",
    "\n",
    "    sample_n = 2000\n",
    "    sample_df = merged_df.sample(n=sample_n, random_state=42) if len(merged_df) > sample_n else merged_df\n",
    "    print(f\"Verwende Sample von {len(sample_df)} für Training/Validierung.\")\n",
    "\n",
    "    # Train-Validate-Test Split\n",
    "    train_data, val_data, test_data_split = perform_train_val_test_split(\n",
    "        sample_df,\n",
    "        train_size=0.8,\n",
    "        val_size=0.15, # Anpassung, damit Summe 1.0 ist, wenn test_size 0.05\n",
    "        test_size=0.05,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"Size of the train split: {train_data.shape}\")\n",
    "    print(f\"Size of the validation split: {val_data.shape}\")\n",
    "    print(f\"Size of the test split: {test_data_split.shape}\")\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "    train_inputs_list, train_labels_list = preprocess_data_for_token_classification(train_data, tokenizer, MAX_LEN)\n",
    "    train_dataset = PatientNotesTokenClassificationDataset(train_inputs_list, train_labels_list)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    val_inputs_list, val_labels_list = preprocess_data_for_token_classification(val_data, tokenizer, MAX_LEN)\n",
    "    val_dataset = PatientNotesTokenClassificationDataset(val_inputs_list, val_labels_list)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Settings\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5) \n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"\\ MPS used\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"\\ CPU used\")\n",
    "    \n",
    "    model.to(device) \n",
    "\n",
    "    # Train\n",
    "    print(\"\\nStarte Training für Token Classification...\")\n",
    "    trained_model = train_bert_token_classification_model(\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epochs=EPOCHS\n",
    "    )\n",
    "\n",
    "    print(\"Token Classification Training abgeschlossen.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # Für das Parsen der Location-Strings\n",
    "\n",
    "\n",
    "def get_char_sets_from_location_str(location_str: str, pn_text_len: int) -> list[set[int]]:\n",
    "    \n",
    "    true_spans_char_sets = []\n",
    "    try:\n",
    "        char_spans_from_str = ast.literal_eval(location_str)\n",
    "        for span_str in char_spans_from_str:\n",
    "            parts = span_str.split()\n",
    "            if len(parts) == 2:\n",
    "                start_char, end_char = int(parts[0]), int(parts[1])\n",
    "                start_char = max(0, start_char)\n",
    "                end_char = min(pn_text_len, end_char) \n",
    "                if start_char < end_char: \n",
    "                    true_spans_char_sets.append(set(range(start_char, end_char)))\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    \n",
    "    return true_spans_char_sets\n",
    "\n",
    "\n",
    "def calculate_overall_example_jaccard(\n",
    "    predicted_char_sets: list[set[int]], \n",
    "    true_char_sets: list[set[int]]\n",
    ") -> float:\n",
    "    \n",
    "    # Union of the predicted annotation spans \n",
    "    union_predicted_chars = set()\n",
    "    for pred_set in predicted_char_sets:\n",
    "        union_predicted_chars.update(pred_set)\n",
    "        \n",
    "    # Union of the true annotation spans\n",
    "    union_true_chars = set()\n",
    "    for true_set in true_char_sets:\n",
    "        union_true_chars.update(true_set)\n",
    "\n",
    "    # Cases if one or both union are empty\n",
    "    if not union_predicted_chars and not union_true_chars:\n",
    "        # Both empty -> prediction correct\n",
    "        return 1.0\n",
    "    if not union_predicted_chars or not union_true_chars:\n",
    "        # opposite case, false prediction \n",
    "        return 0.0\n",
    "\n",
    "    # Calculating the intersection and union of the aggregated characters\n",
    "    intersection_of_unions = len(union_predicted_chars.intersection(union_true_chars))\n",
    "    union_of_unions = len(union_predicted_chars.union(union_true_chars))\n",
    "\n",
    "    if union_of_unions == 0:\n",
    "        return 1.0 if intersection_of_unions == 0 else 0.0 \n",
    "    \n",
    "    return intersection_of_unions / union_of_unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Für eine Fortschrittsanzeige\n",
    "import ast # Für get_char_sets_from_location_str\n",
    "\n",
    "# Extracts a list of character spans (as sets of character indices) from a sequence of predicted token label IDs (B-I-O scheme)\n",
    "def extract_char_spans_from_token_labels(\n",
    "    token_label_ids: list[int], \n",
    "    offset_mapping: list[tuple[int, int]], \n",
    "    sequence_ids: list[int | None],\n",
    "    label_map: dict[str, int]\n",
    ") -> list[set[int]]:\n",
    "    \n",
    "    predicted_char_sets = []\n",
    "    active_span_tokens = [] \n",
    "\n",
    "    b_feature_id = label_map.get('B-FEATURE')\n",
    "    i_feature_id = label_map.get('I-FEATURE')\n",
    "\n",
    "    for i, label_id in enumerate(token_label_ids):\n",
    "        current_token_is_context = (sequence_ids[i] == 1)\n",
    "        token_char_start, token_char_end = offset_mapping[i]\n",
    "        \n",
    "        is_valid_context_token = current_token_is_context and not (token_char_start == 0 and token_char_end == 0)\n",
    "\n",
    "        if label_id == b_feature_id and is_valid_context_token:\n",
    "\n",
    "            if active_span_tokens:\n",
    "                span_start_char = active_span_tokens[0][0]\n",
    "                span_end_char = active_span_tokens[-1][1]\n",
    "                if span_start_char < span_end_char:\n",
    "                    predicted_char_sets.append(set(range(span_start_char, span_end_char)))\n",
    "            \n",
    "            active_span_tokens = [(token_char_start, token_char_end)]\n",
    "        elif label_id == i_feature_id and is_valid_context_token:\n",
    "            if active_span_tokens: \n",
    "                active_span_tokens.append((token_char_start, token_char_end))\n",
    "\n",
    "        else: \n",
    "            if active_span_tokens:\n",
    "                span_start_char = active_span_tokens[0][0]\n",
    "                span_end_char = active_span_tokens[-1][1]\n",
    "                if span_start_char < span_end_char:\n",
    "                    predicted_char_sets.append(set(range(span_start_char, span_end_char)))\n",
    "                active_span_tokens = [] \n",
    "    \n",
    "    if active_span_tokens:\n",
    "        span_start_char = active_span_tokens[0][0]\n",
    "        span_end_char = active_span_tokens[-1][1]\n",
    "        if span_start_char < span_end_char:\n",
    "            predicted_char_sets.append(set(range(span_start_char, span_end_char)))\n",
    "            \n",
    "    return predicted_char_sets\n",
    "\n",
    "\n",
    "def evaluate_token_classification_model(model, tokenizer, df_val, device, max_len, label_map):\n",
    "   \n",
    "    model.eval() \n",
    "    all_jaccards = []\n",
    "    \n",
    "    for _, row in tqdm(df_val.iterrows(), total=df_val.shape[0], desc=\"Validating\"):\n",
    "        question = str(row['feature_text'])\n",
    "        context = str(row['pn_history'])\n",
    "        true_location_str = str(row['location'])\n",
    "        \n",
    "        inputs = tokenizer.encode_plus(\n",
    "            question,\n",
    "            context,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"only_second\",\n",
    "            return_offsets_mapping=True,\n",
    "            return_attention_mask=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "       \n",
    "        offset_mapping_list = inputs['offset_mapping'].squeeze().tolist()\n",
    "        sequence_ids_list = inputs.sequence_ids(0) \n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits \n",
    "            predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist() \n",
    "\n",
    "        # Extract character ranges from the predicted token labels\n",
    "        predicted_char_sets_list = extract_char_spans_from_token_labels(\n",
    "            predicted_label_ids,\n",
    "            offset_mapping_list,\n",
    "            sequence_ids_list,\n",
    "            label_map \n",
    "        )\n",
    "        \n",
    "        # True character spans\n",
    "        true_char_sets_list = get_char_sets_from_location_str(true_location_str, len(context))\n",
    "        \n",
    "        # calculate jaccard score\n",
    "        jaccard_score = calculate_overall_example_jaccard(predicted_char_sets_list, true_char_sets_list)\n",
    "        all_jaccards.append(jaccard_score)\n",
    "        \n",
    "    mean_jaccard = np.mean(all_jaccards) if all_jaccards else 0.0\n",
    "    print(f\"Average Jaccard score on the validation dataset {mean_jaccard:.4f}\")\n",
    "    return mean_jaccard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start evaluation on the validation dataset (Token Classification)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 299/299 [00:12<00:00, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Jaccard score on the validation dataset 0.7164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model.to(device) \n",
    "\n",
    "print(\"\\nStart evaluation on the validation dataset (Token Classification)...\")\n",
    "\n",
    "average_jaccard = evaluate_token_classification_model( \n",
    "    trained_model, \n",
    "    tokenizer, \n",
    "    val_data,      \n",
    "    device, \n",
    "    MAX_LEN,\n",
    "    LABEL_MAP     \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:60: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:60: SyntaxWarning: invalid escape sequence '\\D'\n",
      "/var/folders/rq/0tfx_gzn2tl1v1h_cpzkkdn40000gn/T/ipykernel_49305/1594546117.py:60: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  print(\"\\Detaillierte Counts (für Anzahlen > 3):\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdatensatz (train.csv) geladen mit 14300 Zeilen.\n",
      "\n",
      "--- Verteilung der Anzahl von Annotationen (Spannen) pro Beispiel ---\n",
      "Beispiele mit 0 Annotationen: 4399 (30.76%)\n",
      "Beispiele mit 1 Annotation:  8181 (57.21%)\n",
      "Beispiele mit 2 Annotationen: 1296 (9.06%)\n",
      "Beispiele mit 3 Annotationen: 287 (2.01%)\n",
      "Beispiele mit 4+ Annotationen: 137 (0.96%)\n",
      "--------------------------------------------------------------------\n",
      "Gesamtzahl der verarbeiteten Beispiele: 14300\n",
      "\\Detaillierte Counts (für Anzahlen > 3):\n",
      "  Beispiele mit 4 Annotationen: 99\n",
      "  Beispiele mit 5 Annotationen: 27\n",
      "  Beispiele mit 6 Annotationen: 9\n",
      "  Beispiele mit 7 Annotationen: 1\n",
      "  Beispiele mit 8 Annotationen: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast \n",
    "from collections import Counter\n",
    "\n",
    "DATA_PATH = \"nbme-score-clinical-patient-notes/\" # Passe dies an, falls dein Ordner anders heißt\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Fehler: Die Datei 'train.csv' wurde nicht im Pfad '{DATA_PATH}' gefunden.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Trainingsdatensatz (train.csv) geladen mit {train_df.shape[0]} Zeilen.\")\n",
    "\n",
    "# Liste, um die Anzahl der Spannen pro Zeile zu speichern\n",
    "num_spans_per_row = []\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    location_str = str(row['location'])\n",
    "    list_of_span_strings = ast.literal_eval(location_str)\n",
    "    num_spans_per_row.append(len(list_of_span_strings))\n",
    "    \n",
    "span_counts = Counter(num_spans_per_row)\n",
    "\n",
    "count_0_annotations = span_counts.get(0, 0)\n",
    "count_1_annotation = span_counts.get(1, 0)\n",
    "count_2_annotations = span_counts.get(2, 0)\n",
    "count_3_annotations = span_counts.get(3, 0)\n",
    "count_more_than_3_annotations = 0\n",
    "\n",
    "for num, count in span_counts.items():\n",
    "    if num >= 4:\n",
    "        count_more_than_3_annotations += count\n",
    "\n",
    "total_examples_processed = len(num_spans_per_row)\n",
    "\n",
    "print(\"\\n--- Verteilung der Anzahl von Annotationen (Spannen) pro Beispiel ---\")\n",
    "print(f\"Examples with 0 annotations: {count_0_annotations} ({count_0_annotations/total_examples_processed:.2%})\")\n",
    "print(f\"Examples with 1 annotations:  {count_1_annotation} ({count_1_annotation/total_examples_processed:.2%})\")\n",
    "print(f\"Examples with 2 annotations {count_2_annotations} ({count_2_annotations/total_examples_processed:.2%})\")\n",
    "print(f\"Examples with 3 annotations: {count_3_annotations} ({count_3_annotations/total_examples_processed:.2%})\")\n",
    "print(f\"Examples with 4+ annotations: {count_more_than_3_annotations} ({count_more_than_3_annotations/total_examples_processed:.2%})\")\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(f\"Total count of annotations: {total_examples_processed}\")\n",
    "\n",
    "print(\"\\Detailled Counts (with more than 3):\")\n",
    "for num, count in sorted(span_counts.items()):\n",
    "    if num > 3:\n",
    "        print(f\"  Examples with {num} annotations: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
